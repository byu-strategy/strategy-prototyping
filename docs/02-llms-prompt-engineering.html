<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.33">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>LLMs &amp; Prompting – MSB 341 - Product Management / STRAT 490R - Creating Digital Products with AI: Strategy &amp; Prototyping</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./03-product-innovation.html" rel="next">
<link href="./01-pm-ai-era.html" rel="prev">
<link href="./images/prototyping-favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea385d0e468b0dd5ea5bf0780b1290d9.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-485d01fc63b59abcd3ee1bf1e8e2748d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
</head><body class="nav-sidebar floating quarto-light"><header class="book-header-banner">
  <a href="https://byu-strategy.github.io/program-guide/" target="_blank">
    <img src="images/strat-logo.png" alt="BYU Strategy - Marriott School of Business">
  </a>
</header>

<!-- Google tag (gtag.js) -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-5TPMPSE4HZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5TPMPSE4HZ');
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">




<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-pm-ai-era.html">Topics</a></li><li class="breadcrumb-item"><a href="./02-llms-prompt-engineering.html"><span class="chapter-title">LLMs &amp; Prompting</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MSB 341 - Product Management / STRAT 490R - Creating Digital Products with AI: Strategy &amp; Prototyping</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Course Information</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Syllabus</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-schedule.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Schedule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00-assessments.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Assessments</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-pm-ai-era.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">AI Product Management</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-llms-prompt-engineering.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">LLMs &amp; Prompting</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-product-innovation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Product Innovation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-value-prop-design.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Prototying and MVP</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-project-management-jira.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Project Management</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-collaboration-git-triad.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">GitHub &amp; Collaboration</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-internet-fundamentals.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">APIs &amp; Internet Fundamentals</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-software-engineering.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">SWE Principles</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-ai-dev-platforms.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">AI Dev Tools</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-build-feedback-1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Build Session 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-product-metrics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Product Metrics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-build-feedback-2.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Build Session 2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14-final-presentations.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Final Presentations</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./97-resources.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Resources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./98-tools.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">AI Tools Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./99-prompts.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Prompt Library</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#ai-and-machine-learning" id="toc-ai-and-machine-learning" class="nav-link active" data-scroll-target="#ai-and-machine-learning">AI and Machine Learning</a>
  <ul class="collapse">
  <li><a href="#supervised-learning" id="toc-supervised-learning" class="nav-link" data-scroll-target="#supervised-learning">Supervised Learning</a></li>
  <li><a href="#neural-networks" id="toc-neural-networks" class="nav-link" data-scroll-target="#neural-networks">Neural Networks</a></li>
  <li><a href="#large-language-models-and-generative-ai" id="toc-large-language-models-and-generative-ai" class="nav-link" data-scroll-target="#large-language-models-and-generative-ai">Large Language Models and Generative AI</a></li>
  <li><a href="#gpt-architecture" id="toc-gpt-architecture" class="nav-link" data-scroll-target="#gpt-architecture">GPT Architecture</a></li>
  </ul></li>
  <li><a href="#prompting" id="toc-prompting" class="nav-link" data-scroll-target="#prompting">Prompting</a>
  <ul class="collapse">
  <li><a href="#programmatic-prompting" id="toc-programmatic-prompting" class="nav-link" data-scroll-target="#programmatic-prompting">Programmatic Prompting</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./01-pm-ai-era.html">Topics</a></li><li class="breadcrumb-item"><a href="./02-llms-prompt-engineering.html"><span class="chapter-title">LLMs &amp; Prompting</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">LLMs &amp; Prompting</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="ai-and-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="ai-and-machine-learning">AI and Machine Learning</h2>
<p>To get the most out of AI and in particular if you plan to build AI powered products (which is different than simply building a product with the help of AI), you need to understand how this technology works, at least at a high level. Artificial Intelligence (AI) is the broad idea of creating computer systems that can perform tasks we normally associate with human intelligence, like understanding language, recognizing patterns, making decisions, and generating creative content.</p>
<p>Machine Learning (ML) is a subset of AI that focuses on teaching computers to learn from data instead of following hard-coded instructions. In ML, we give the computer many examples (data) and let it find the patterns on its own. The more and better-quality data it sees, the better it gets at making predictions or generating useful outputs.</p>
<p>Within machine learning, deep learning uses layers of artificial “neurons”, called a neural network, to handle extremely complex patterns this is the technology behind most modern breakthroughs, including Large Language Models (LLMs) like ChatGPT.</p>
<p>Even if you won’t be building AI models, understanding the basics concepts of how they are developed will help you ask the right questions, spot opportunities for AI in products, and work effectively with technical teams.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-ml-map.png" class="img-fluid figure-img"></p>
<figcaption>Image source: Build a Large Language Model (From Scratch) by Sebastian Raschka</figcaption>
</figure>
</div>
<section id="supervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="supervised-learning">Supervised Learning</h3>
<p>The branch of machine learning that powers today’s Generative AI breakthroughs is supervised learning. The term “supervised” refers to the fact that the mathematical model is guided by correct answers from a <em>ground-truth</em> dataset (actual data from the real world), allowing it to learn the mapping from inputs to outputs. These correct answers are often referred to as the <em>labels</em> in a labeled data set. An example is training a model to guess the next word in a sentence by giving it lots of past examples of actual sentences.</p>
<p>For instance, imagine we train a model on sentences like:</p>
<ul>
<li>The cat sat on the <strong>mat</strong>.</li>
<li>She went to the <strong>store</strong>.</li>
<li>I like to eat <strong>pizza</strong>.</li>
</ul>
<p>In each case, the words before the bolded one can be considered the <strong>input</strong>, and the bolded final word is the <strong>label</strong> (correct answer or ground-truth). After using many examples to train a model, we can apply the model to new sentences to infer the best next word given any text input.</p>
<p>In short: <strong>supervised learning is learning patterns from labeled examples so you can make accurate predictions on new, unseen data.</strong></p>
<p>The simplest form of supervised learning is <strong>simple linear regression</strong>, where the goal is to predict a straight line (linear) relationship between an output variable one or more input variables.</p>
<p>A simple linear regression model takes a single <strong>input variable</strong> <span class="math inline">\(x\)</span> and predicts the value of a corresponding <strong>output variable</strong> <span class="math inline">\(y\)</span>. For example, the input variable might represent a house’s <em>square footage</em>, and the output variable could represent the <em>value</em> of the home.</p>
<p>We can write down the relationship between <em>square footage</em> and <em>value</em> in the form of a mathematical equation (also called a mathematical <em>function</em> or a <em>model</em>):</p>
<p><span class="math display">\[
\hat{y} = w_0 + w_1 x
\]</span></p>
<p>Where <span class="math inline">\(\hat{y}\)</span> (pronounced <em>y-hat</em>)represents the predicted home <em>value</em> and <span class="math inline">\(x\)</span> represents the <em>square footage</em>.</p>
<p>In machine learning jargon <span class="math inline">\(w_0\)</span> and <span class="math inline">\(w_1\)</span> are called the <strong>parameters</strong> or <strong>weights</strong> of the model (hence the use of <span class="math inline">\(w\)</span> in the notation) and describe the nature of the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(\hat{y}\)</span>. <span class="math inline">\(w_0\)</span> and <span class="math inline">\(w_1\)</span> are the numbers that the computer will <em>learn</em> (i.e.&nbsp;derive) based on what is observed in real life which will be represented in a <em>training dataset</em> that consists of many input–output pairs.</p>
<p>The straight line in the image below helps you visualize the estimated linear relationship that can be learned between an output and an input such as square-footage. The dotted lines connecting the individual data points to the fitted red line show how far off the model predictions are from ground truth. The process of training a model tries out different values for the paramaters as it searches for the ones that will minimize the prediction errors. The way you compute the prediction error is called the “<strong>loss function</strong>” (in this case, the loss function could be defined as: <span class="math inline">\(|predicted - actual|\)</span>). The name for this iterative algorithm that looks for the best possible weights is called <strong>gradient descent.</strong></p>
<div class="callout callout-style-default callout-tip callout-titled" title="What is gradient descent?">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is gradient descent?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Gradient descent is a family of machine learning algorithms that update a model’s parameters (weights) so that they can make better predictions over time. The word “gradient” refers to multivariate version of a derivative (rate of change) from calculus. The rate of change in this context is how quickly the prediction error changes when you change model parameters.</p>
<p>An analogy will help with the intuition. Imagine the height of a hillside represents the sum of all the prediction errors. The point where you are standing on the hillside represents the current model parameters (weights). The goal is to get down the hill onto the valley floor (which implies reducing the prediction error) as fast as possible by taking the steepest path down. Each step down corresponds to a testing out a different set of model parameters to see how accurate the model predictions become. The gradient (i.e.&nbsp;the rate of change in the prediction error as the model parameters are adjusted) is computed and tells you which direction is steepest. You take another step (i.e.&nbsp;smartly choose new values for the parameters) and keep repeating this process until you are confident you’ve found the model paramaters that minimize the prediction error.</p>
</div>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/slr-loss.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
<p>While linear regression is useful for modeling straight-line relationships between inputs and outputs, we need something much more flexible to capture the complexity of human language. <strong>Neural networks</strong> provide such a tool. First inspired in the 1940s as mathematical models of the brain, they languished for decades but are now realizing their full potential, with large datasets and powerful hardware enabling complex networks to excel in vision and language applications.</p>
</section>
<section id="neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="neural-networks">Neural Networks</h3>
<p>Like linear regression, a neural network is fundamentally a mathematical function that defines a relationship between inputs and outputs. A deep understanding of neural networks is beyond the scope of this course, but we will at least introduce a visual and show the mathematical function to give you some sense for what’s going on under the hood.</p>
<p>A simple neural network can be written as:</p>
<p><span class="math display">\[
\hat{y} = f\!\big(W^{(2)}\, g(W^{(1)} x + b^{(1)}) + b^{(2)}\big)
\]</span> Where:</p>
<ul>
<li><span class="math inline">\(W\)</span>s are matrices containing the model weights (parameters)</li>
<li><span class="math inline">\(x\)</span> is now a vector of inputs (1 or many inputs),</li>
<li><span class="math inline">\(b\)</span>s are analogous to intercept terms (called “bias”)</li>
<li><span class="math inline">\(f(\cdot)\)</span> and <span class="math inline">\(g(\cdot)\)</span> are referred to as activation functions</li>
</ul>
<p>As you can see in the above equation, a neural network is a composite a several functions. For larger neuron networks many functions are nested.</p>
<p>Neural networks are often described in visual terms like in the image below:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/single-layer-nn.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
<p>A neural network is organized into layers that gradually transform inputs into a prediction. The first layer, called the input layer, represents the features we provide to the model. In the home value example, the inputs might be the square footage of the home and the number of bedrooms. A bias input fixed at 1 is also included, giving the network more flexibility to shift its predictions up or down regardless of the raw feature values. Each circle in the diagram is called a neuron or unit, and the lines connecting them are referred to as edges. Each edge represents a weight or bias parameter that the model learns during training. These inputs are passed into the hidden layer, where each neuron acts like a mini regression equation of its own. Each neuron computes a weighted sum of the inputs, adds its bias, and then applies a function we call <span class="math inline">\(g\)</span>. This is known as an activation function, and its role is to bend straight-line relationships into curves so the network can capture more complex patterns. For instance, in our housing example, <span class="math inline">\(g\)</span> might allow the model to learn that the first 500 square feet add a lot of value, while additional square footage adds less. Without this step, the network would behave just like plain linear regression.</p>
<p>Finally, the hidden layer feeds into the output layer. Here, the activations are combined again using new weights and a bias, and then passed through another function, usually called <span class="math inline">\(f\)</span>. You can think of <span class="math inline">\(f\)</span> as the final shaping step that ensures the prediction is in the right form for the task. For predicting home prices, <span class="math inline">\(f\)</span> might simply output a dollar amount. For classification problems, <span class="math inline">\(f\)</span> might produce a probability between 0 and 1.</p>
<p>Whereas simple linear regression has just two parameters to estimate (a slope and an intercept), the small neural network in the diagram already has 13 parameters. The number of parameters grows quickly as networks get larger, which is what gives them the ability to represent more complex relationships. Modern neural networks that power chatbots such as ChatGPT are astonishingly large by comparison, containing hundreds of billions of parameters. GPT-3, for example, was trained with 175 billion parameters, and the newest generations are even larger. This massive scale enables them to capture subtle patterns in language, context, and reasoning, allowing them to generate coherent, human-like responses.</p>
<p>Of course, this complexity comes with trade-offs: training such large models requires enormous amounts of data, specialized hardware such as GPUs and TPUs, and advanced optimization techniques. But the underlying principle is the same as in the small housing example above where each parameter represents a weight or bias that adjusts how inputs are transformed into outputs. The difference is simply one of scale.</p>
<p>You won’t need to fully understand or know the math behind neural networks for this course, but you should at least see it once which many people never do. The neural network shown in the visualization above is written mathematically in the steps that follow:</p>
<p>All of the weights associated with the edges are combined into a weight matrix and bias vector. The weight associated with the transition from the input layer the hidden layer is shown first followed by the weights and bias that transform the hidden layer into the final output.</p>
<p><span class="math display">\[
W^{(1)} \in \mathbb{R}^{3 \times 2} =
\begin{bmatrix}
w^{(1)}_{11} &amp; w^{(1)}_{12} \\
w^{(1)}_{21} &amp; w^{(1)}_{22} \\
w^{(1)}_{31} &amp; w^{(1)}_{32}
\end{bmatrix},
\quad
b^{(1)} \in \mathbb{R}^{3} \;=\;
\begin{bmatrix}
b^{(1)}_{1} \\
b^{(1)}_{2} \\
b^{(1)}_{3}
\end{bmatrix}
\]</span></p>
<p><span class="math display">\[
W^{(2)} \in \mathbb{R}^{1 \times 3} =
\begin{bmatrix}
w^{(2)}_{11} &amp; w^{(2)}_{12} &amp; w^{(2)}_{13}
\end{bmatrix},
\quad
b^{(2)} \in \mathbb{R} \;=\;
\begin{bmatrix}
b^{(2)}_{1}
\end{bmatrix}
\]</span> These can be plugged into the matrix equation that we first showed.</p>
<p><span class="math display">\[
\hat{y} \;=\; f\!\Big(W^{(2)}\, g\!\big(W^{(1)} x + b^{(1)}\big) + b^{(2)}\Big)
\]</span> After doing the matrix computations, the formula would expand into this long set of additions and multiplications.</p>
<p><span class="math display">\[
\hat{y}
=
f\!\Big(
w^{(2)}_{11}\, g\!\big(w^{(1)}_{11} x_1 + w^{(1)}_{12} x_2 + b^{(1)}_1\big)
+
w^{(2)}_{12}\, g\!\big(w^{(1)}_{21} x_1 + w^{(1)}_{22} x_2 + b^{(1)}_2\big)
+
w^{(2)}_{13}\, g\!\big(w^{(1)}_{31} x_1 + w^{(1)}_{32} x_2 + b^{(1)}_3\big)
+
b^{(2)}_{1}
\Big)
\]</span> Common choices of function for <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are shown below:</p>
<p><span class="math display">\[
f(z) = \sigma(z) = \frac{1}{1 + e^{-z}}
\]</span></p>
<p><span class="math display">\[
\quad
g(z) = \text{ReLU (Rectified Linear Unit)} = \max(0, z)
\]</span> Modern AI models take text and break it into smaller pieces called <strong>tokens.</strong> A token might be a whole word, part of a word, or even a single character. Each token is then converted into numbers through a process called <strong>embedding</strong>, which represents it as a vector of numbers that captures aspects of its meaning and how it relates to other tokens.</p>
<p>Embeddings are a way to turn different kinds of information like text, audio, or video—into numbers so a computer can work with them.</p>
<p>An embedding model is itself a deep neural network that takes raw input (words, sounds, images, etc.) and converts it into a list of numbers that captures the meaning or important features of the input (i.e.&nbsp;a vector). Two inputs with similar meanings will have vectors that are close to each other, even if the exact words, sounds, or images are different.</p>
<p>Embeddings are like coordinates on a map of word meanings. They let computers compare, search, and work with language in a numerical and mathematical way.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/embedding.png" class="img-fluid figure-img"></p>
<figcaption>Image source: Build a Large Language Model (From Scratch) by Sebastian Raschka</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/embedding-plot.png" class="img-fluid figure-img"></p>
<figcaption>Image source: Build a Large Language Model (From Scratch) by Sebastian Raschka</figcaption>
</figure>
</div>
<p>The model typically takes a sequence of token embeddings, for example, a batch representing 10 or so words, as input and is trained to predict the next word in the sequence. During training, it learns from vast collections of text such as books, articles, blogs, and other digital sources, which serve as the ground truth.</p>
<p>Once the text has been converted into numbers, the neural network processes these vectors layer by layer, using weights, biases, and activation functions to detect patterns and relationships. With each layer, the model refines its understanding of the context, and at the end of the process, it produces a probability distribution over possible next words and selects the most likely one.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/next-word.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption>Image by Sebastian Raschka</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/next-word-numbers.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption>Image by Sebastian Raschka</figcaption>
</figure>
</div>
<p>Image source: Build a Large Language Model (From Scratch) by Sebastian Raschka</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-data.webp" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
<p>To summarize our discussion, modern AI models are ultimately created from 4 foundational ingredients:</p>
<ol type="1">
<li><strong>A mathematical model:</strong> This defines the form of the mathematical relationship used to relate inputs to outputs, for example, a straight line (linear) or a more flexible structure like a neural network (non-linear).</li>
<li><strong>Training data:</strong> A collection of real-world examples that pair inputs with their corresponding outputs. The quality and relevance of this data are crucial to how well the model can learn and make accurate predictions. In the case of LLMs, the training data is a gigantic corpus of text (i.e.&nbsp;books, blogs, etc.)</li>
<li><strong>A “loss” function:</strong> A mathematical expression that measures how far off the model’s predictions are from the correct answers found in the train data. The loss function provides feedback on prediction accuracy and helps the model improve over time.</li>
<li><strong>A training algorithm:</strong> A step-by-step procedure that combines the first three ingredients in a way that minimizes the prediction errors produced by the model. This is where the so-called <em>learning</em> takes place. Modern AI models are trained using algorithms based on <em>gradient descent.</em></li>
</ol>
</section>
<section id="large-language-models-and-generative-ai" class="level3">
<h3 class="anchored" data-anchor-id="large-language-models-and-generative-ai">Large Language Models and Generative AI</h3>
<p>Large Language Models (LLMs) are built using massive neural networks and are the core technology behind much of today’s Generative AI. They are built in two main stages: <strong>pretraining</strong> and <strong>fine-tuning</strong></p>
<section id="gathering-and-processing-text-data" class="level4">
<h4 class="anchored" data-anchor-id="gathering-and-processing-text-data">1. Gathering and Processing Text Data</h4>
<p>The process begins by collecting an enormous body of text from a variety of sources, including internet articles, books, Wikipedia, and research papers. This raw text can contain trillions of words. Before a model can use it, the text is converted into numbers through a process called <em>tokenization</em>. Each word or piece of a word is represented as a vector (a list of numbers) so the computer can process it mathematically.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/tokenization.png" class="img-fluid figure-img"></p>
<figcaption>Image source: Build a Large Language Model (From Scratch) by Sebastian Raschka</figcaption>
</figure>
</div>
</section>
<section id="pretraining-the-model" class="level4">
<h4 class="anchored" data-anchor-id="pretraining-the-model">2. Pretraining the Model</h4>
<p>Using this massive numerical dataset, the model is trained to perform one fundamental task: predicting the next word in a sequence. By doing this billions of times, it learns grammar, facts about the world, reasoning patterns, and relationships between concepts. After pretraining, the LLM becomes a <strong>foundation model</strong> with basic capabilities such as:</p>
<ul>
<li><strong>Text completion</strong> – finishing a sentence or paragraph.</li>
<li><strong>Few-shot learning</strong> – adapting to new tasks with just a few examples in the prompt.</li>
</ul>
</section>
<section id="fine-tuning-for-specific-tasks" class="level4">
<h4 class="anchored" data-anchor-id="fine-tuning-for-specific-tasks">3. Fine-Tuning for Specific Tasks</h4>
<p>Pretraining gives the model broad language skills, but it’s still general-purpose. Fine-tuning makes it specialized. In this stage, the pretrained model is trained again on a <em>labeled dataset</em>—data where each input has a known, correct output. This allows the LLM to excel at targeted applications such as:</p>
<ul>
<li><strong>Classification</strong> – sorting emails as spam or not spam.</li>
<li><strong>Summarization</strong> – condensing long documents into key points.</li>
<li><strong>Translation</strong> – converting text between languages.</li>
<li><strong>Conversational assistance</strong> – answering questions and performing tasks as a chatbot or virtual assistant.</li>
</ul>
</section>
<section id="the-big-picture" class="level4">
<h4 class="anchored" data-anchor-id="the-big-picture">4. The Big Picture</h4>
<ul>
<li><strong>Pretraining</strong> = learning the <em>general rules of language and knowledge</em>.</li>
<li><strong>Fine-tuning</strong> = specializing for <em>specific, high-performance applications</em>.</li>
</ul>
<p>Together, these steps create powerful AI systems capable of generating text, answering questions, and performing a wide variety of language-based tasks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/llm-overview.png" class="img-fluid figure-img"></p>
<figcaption>Image source: Build a Large Language Model (From Scratch) by Sebastian Raschka</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/llm-process.png" class="img-fluid figure-img"></p>
<figcaption>Image source: Build a Large Language Model (From Scratch) by Sebastian Raschka</figcaption>
</figure>
</div>
</section>
</section>
<section id="gpt-architecture" class="level3">
<h3 class="anchored" data-anchor-id="gpt-architecture">GPT Architecture</h3>
<p>Digging into the full details of the GPT architecture is beyond the scope of this course. However, it’s useful to recognize diagrams like this, which present the high-level structure of the model. At the bottom, tokenized text (converted into numerical tokens) passes through an embedding layer that maps each token to a numerical vector. A positional embedding layer adds information about word order.</p>
<p>The heart of GPT is the transformer block (shaded in blue), repeated many times (e.g., 12 layers for GPT-2 Small, 48 for GPT-2 XL). Each block contains:</p>
<ul>
<li>Masked multi-head attention – allows the model to focus on relevant words in the input while preventing it from “seeing” future words during training.</li>
<li>Feed-forward layers – process and transform the attention outputs.</li>
<li>Layer normalization and dropout – improve stability and reduce overfitting.</li>
</ul>
<p>Each layer in the GPT architecture is part of a deep neural network and performs a sequence of mathematical operations—primarily matrix multiplications and additions—that transform the input vectors into increasingly abstract representations of the text. During training, the model’s parameters (weights) are adjusted using gradient descent, an optimization process that reduces prediction errors by calculating how much each weight should change based on the difference between the model’s output and the correct answer.</p>
<p>After going through all the layers, the model tidies up its final internal calculations and then turns them into a list of possible next words, each with a score for how likely it is to come next. The word with the highest score is usually chosen as the model’s prediction.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/gpt.png" class="img-fluid figure-img"></p>
<figcaption>Image source: Build a Large Language Model (From Scratch) by Sebastian Raschka</figcaption>
</figure>
</div>
</section>
</section>
<section id="prompting" class="level2">
<h2 class="anchored" data-anchor-id="prompting">Prompting</h2>
<p>Now that we understand a bit about what powers modern AI, let’s get practical and discuss prompting techinques to get the most out of it.</p>
<p>Prompts come in many shapes, depending on your goals, the complexity of the task, and how much control you need over the AI’s output. Understanding the anatomy of different prompt structures helps you choose the right one for the job.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 29%">
<col style="width: 27%">
<col style="width: 20%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>Prompt Type</th>
<th>What it is</th>
<th>Example</th>
<th>Best for</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Single-Turn Prompt</strong></td>
<td>A one-off instruction or question sent to the model.</td>
<td>Summarize this article in three bullet points.</td>
<td>Quick tasks where context isn’t needed beyond the immediate request.</td>
</tr>
<tr class="even">
<td><strong>Role-Based Prompt</strong></td>
<td>Sets a clear role or persona for the AI to adopt.</td>
<td>You are an experienced product manager. Draft a launch plan for a new mobile app.</td>
<td>When tone, perspective, or expertise level matters.</td>
</tr>
<tr class="odd">
<td><strong>Context + Instruction Prompt</strong></td>
<td>Combines background information with a direct request.</td>
<td>Background: Our company sells eco-friendly cleaning products online. Task: Write a short ad targeting parents concerned about chemical safety.</td>
<td>When the model needs background to produce relevant results.</td>
</tr>
<tr class="even">
<td><strong>Few-Shot Prompt</strong></td>
<td>Includes examples of desired input-output pairs to guide the model’s style or format.</td>
<td>Q: What is the capital of France? A: Paris<br>Q: What is the capital of Germany? A: Berlin<br>Q: What is the capital of Italy? A:</td>
<td>Training the model in your preferred style or pattern without fine-tuning.</td>
</tr>
<tr class="odd">
<td><strong>Multi-Turn Conversation</strong></td>
<td>A back-and-forth exchange where previous messages build context.</td>
<td>User: Give me a list of U.S. national parks in the West.<br>AI: [List]<br>User: Now sort them by size.</td>
<td>Complex tasks where you refine or expand the request over time.</td>
</tr>
<tr class="even">
<td><strong>Dynamic, Variable-Injected Prompt</strong></td>
<td>A template where parts of the prompt are filled in with live or changing data.</td>
<td>Write a {tone} introduction to {topic} for someone named {name}.</td>
<td>Automation, personalization, and programmatic API workflows.</td>
</tr>
</tbody>
</table>
<p>By mixing and matching these structures, you can create prompts that are concise, rich in context, and tailored for automation and enabling far more consistent and useful AI outputs.</p>
<section id="programmatic-prompting" class="level3">
<h3 class="anchored" data-anchor-id="programmatic-prompting">Programmatic Prompting</h3>
<p>AI’s impact grows dramatically when you automate prompts and dynamically inject fresh data into them.</p>
<p>The python code chunk below illustrates how to do this.</p>
<div id="07de3bb6" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> openai <span class="im">import</span> OpenAI</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Config ---</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>INPUT_CSV <span class="op">=</span> <span class="st">"input.csv"</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>OUTPUT_CSV <span class="op">=</span> <span class="st">"output.csv"</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>MODEL <span class="op">=</span> <span class="st">"gpt-4o-mini"</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>SYSTEM_PROMPT <span class="op">=</span> <span class="st">"You are a helpful assistant."</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>API_KEY <span class="op">=</span> os.getenv(<span class="st">"OPENAI_API_KEY"</span>, <span class="st">"YOUR_OPENAI_API_KEY"</span>)  <span class="co"># or set env var</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Client ---</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> OpenAI(api_key<span class="op">=</span>API_KEY)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Load data ---</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(INPUT_CSV)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure expected columns exist</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> [<span class="st">"name"</span>, <span class="st">"topic"</span>, <span class="st">"tone"</span>]:</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> col <span class="kw">not</span> <span class="kw">in</span> df.columns:</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Missing required column: </span><span class="sc">{</span>col<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> call_api(row, retries<span class="op">=</span><span class="dv">3</span>, backoff<span class="op">=</span><span class="fl">2.0</span>):</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Call OpenAI once per row with simple retry/backoff."""</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> <span class="ss">f"Write a </span><span class="sc">{</span>row[<span class="st">'tone'</span>]<span class="sc">}</span><span class="ss"> introduction to </span><span class="sc">{</span>row[<span class="st">'topic'</span>]<span class="sc">}</span><span class="ss"> for someone named </span><span class="sc">{</span>row[<span class="st">'name'</span>]<span class="sc">}</span><span class="ss">."</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> attempt <span class="kw">in</span> <span class="bu">range</span>(retries):</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>            resp <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>                model<span class="op">=</span>MODEL,</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>                messages<span class="op">=</span>[</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>                    {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: SYSTEM_PROMPT},</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>                    {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: prompt},</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>                temperature<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Newer client returns attributes, not dicts:</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> resp.choices[<span class="dv">0</span>].message.content.strip()</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> attempt <span class="op">==</span> retries <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> <span class="ss">f"Error: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>            time.sleep(backoff <span class="op">**</span> attempt)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Run generation ---</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"response"</span>] <span class="op">=</span> df.<span class="bu">apply</span>(call_api, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Save results ---</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>df.to_csv(OUTPUT_CSV, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Done. Wrote </span><span class="sc">{</span><span class="bu">len</span>(df)<span class="sc">}</span><span class="ss"> rows to </span><span class="sc">{</span>OUTPUT_CSV<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This script reads a CSV, sends each row’s data to the OpenAI API, and saves the responses to a new CSV.</p>
<p><strong>Flow:</strong><br>
<code>input.csv → Pandas DataFrame → AI prompt → OpenAI API → response → output.csv</code></p>
<p>A more detailed summary of what the code does is below:</p>
<ol type="1">
<li><strong>Import libraries</strong> – <code>pandas</code> for CSV handling, <code>openai</code> for API calls, <code>time</code> for retries.</li>
<li><strong>Config settings</strong> – file paths, model name, system prompt, API key.</li>
<li><strong>Create client</strong> – <code>client = OpenAI(api_key=API_KEY)</code> to connect to OpenAI.</li>
<li><strong>Load CSV</strong> – <code>df = pd.read_csv(INPUT_CSV)</code> stores the spreadsheet in a DataFrame.</li>
<li><strong>Check columns</strong> – ensure <code>name</code>, <code>topic</code>, and <code>tone</code> exist.</li>
<li><strong>Define <code>call_api()</code></strong> – builds a dynamic prompt, sends it to the API, retries if needed.</li>
<li><strong>Apply function</strong> – <code>df["response"] = df.apply(call_api, axis=1)</code> runs the prompt for each row.</li>
<li><strong>Save output</strong> – <code>df.to_csv(OUTPUT_CSV, index=False)</code> writes results to a new file.</li>
</ol>


</section>
</section>

</main> <!-- /main -->
<footer class="book-footer">
  <div class="footer-content">
    <div class="footer-left">
      <img src="images/strat-logo.png" alt="BYU Logo" class="footer-logo">
    </div>
    <div class="footer-right">
      <a href="https://www.scottmurff.org" target="_blank">Scott Murff</a>
      |
      <a href="https://www.linkedin.com/in/scottdmurff" target="_blank">LinkedIn</a>
    </div>
  </div>
</footer>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./01-pm-ai-era.html" class="pagination-link" aria-label="AI Product Management">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">AI Product Management</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./03-product-innovation.html" class="pagination-link" aria-label="Product Innovation">
        <span class="nav-page-text"><span class="chapter-title">Product Innovation</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>