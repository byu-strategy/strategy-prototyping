---
title: "AI Product Management"
---

## History of Product Management

At its simplest, product management is about identifying customer needs, aligning them with business goals, and working with cross-functional teams to build products that succeed in the market. The person responsible is the Product Manager (PM), often called the "CEO of the product."

Some people take issue with the “CEO” comparison, since product managers typically influence without formal authority and often don’t have many direct reports. Still, like a CEO, the skills of a product manager are broad and typically include:

-   Strategic thinking – setting vision, making trade-offs, and aligning with business goals
-   Customer insight – understanding user needs and pain points
-   Analytical ability – using data and critical thinking to guide decisions
-   Technical & design fluency – collaborating effectively with engineers and designers
-   Execution & organization – planning roadmaps, prioritizing, and delivering results
-   Communication & leadership – influencing, storytelling, and managing stakeholders

Products can be hardware or software, but since software dominates in volume, product management is often associated with software, even though many of the principles can apply equally well to hardware. Today, many hardware products come with a software component or integrated app, at times blurring the line between hardware and software. The focus of this course will software (i.e. digital products).

Product management, as a named discipline and job title, began at HP in the 1940s and has since evolved into a key driver of innovation in technology. Early influences such as the \[Scrum development process\](https://en.wikipedia.org/wiki/Scrum\_(software_development) and the [Agile Manifesto](https://agilemanifesto.org/) reshaped how products are built, while initiatives like Google’s Associate Product Manager (APM) program and influential books helped standardize best practices. In recent years, PM has become one of the most sought-after careers, and today the field is entering a new era with the rise of the AI Product Manager.

![A History of Product Management; Aakash Gupta and Scott Murff](images/pm-history.png)

The personal computer revolution of the 1980s brought computing into offices and homes. The rise of the internet in the 1990s connected the world and created entirely new industries, from e-commerce to online media. In the 2000s, broadband (i.e. high-speed internet access) and cloud computing made software cheaper to build, scale, and distribute, while the launch of the iPhone in 2007 ushered in the smartphone era putting powerful applications directly into billions of people’s hands.

In 2011, Marc Andreessen, co-founder of the venture capital firm Andreessen Horowitz (a16z) (known for its influential early investments in companies like Facebook, Airbnb, and Coinbase) famously observed that [*Software Is Eating the World*](https://a16z.com/why-software-is-eating-the-world/).

AI now appears to be on track to “eat the world” again, this time at a much faster pace. The launch of ChatGPT on November 30, 2022, marked a turning point, catalyzing mass adoption of generative AI and enabling the rise of the AI Product Manager.

Marc now predicts that [*AI Will Save the World*](https://a16z.com/ai-will-save-the-world/), but this certainly won't happen automatically. Because human nature is what it is, there will be plenty of people using AI in ways that are damaging to both individuals and society. Indeed, we are living in the time when:

> “Discoveries latent with such potent power, either for the blessing or the destruction of human beings as to make men’s responsibility in controlling them the most gigantic ever placed in human hands. … This age is fraught with limitless perils, as well as untold possibilities.” *--David O. McKay, in Conference Report, Oct. 1966, 4.*

**You have the incredibly exciting and challenging opportunity to harness AI to improve the world. This class will help prepare you to seize that opportunity.**

Over the past two decades, many companies adopted a *product trio* team structure for building software products. This structure brings together three complementary roles: the product manager, who defines the vision, strategy, and priorities; the designer, who ensures usability, aesthetics, and a seamless user experience; and one or more engineers, who turn ideas into functional, scalable solutions. By balancing business objectives, user needs, and technical feasibility, the trio has emerged as a proven way to foster cross-functional collaboration and accelerate product development.

AI and the tools we will use in this course are having a major impact and disrupting what had become a stable organizational model. This is true because AI changes both the division of labor within the trio and the speed and scale at which individuals and teams can operate.

## AI Product Management

With AI, a PM can quickly generate wireframes, mockups, or even working product demos without waiting on design or engineering support. Instead of handing off abstract requirements, they can test tangible ideas with users in days, not weeks. This doesn’t eliminate the need for designers and engineers, but it shifts when and how they are engaged. Designers can focus on higher-fidelity experience and brand expression, while engineers concentrate on scalability, integration, and technical soundness.

It remains to be seen how this will fully play out, but early indications suggest that shifts in how PMs, designers, and engineers work together are real and lasting. With the right AI tools some ambitious individuals may be able to wear all three hats to varying degrees.

Below are a selection of anecdotes from leaders in the field that provides some insight into how things are shifting.

::: tweet-center
<blockquote class="twitter-tweet">

<p lang="en" dir="ltr">

Builder’s high is back...

</p>

— Madhu Guru (@realmadhuguru) <a href="https://twitter.com/realmadhuguru/status/1955451011323314641">August 13, 2025</a>

</blockquote>
:::

```{=html}
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
```

::: tweet-center
<blockquote class="twitter-tweet">

<p lang="en" dir="ltr">

We are adding a coding section to all of our Product Managers interviews at <a href="https://twitter.com/Shopify?ref_src=twsrc%5Etfw">@Shopify</a>.<br><br> We'll start with APM interviews. We expect candidates to build a prototype of the product they suggested in the case interview.<br><br> There is no excuse for PMs not building prototypes.

</p>

— Kaz Nejatian (@CanadaKaz) <a href="https://twitter.com/CanadaKaz/status/1955629733460562404?ref_src=twsrc%5Etfw"> August 13, 2025 </a>

</blockquote>
:::

```{=html}
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
```

::: tweet-center
<blockquote class="twitter-tweet">

<p lang="en" dir="ltr">

Vibe coding is here to stay. I'd been worried it might be a fad, but I talked to the founder of an infrastructure company who's in a position to see how well vibe-coded apps are doing, and he said a lot of them are making money.

</p>

— Paul Graham (@paulg) <a href="https://twitter.com/paulg/status/1956458026652799173?ref_src=twsrc%5Etfw"> August 15, 2025 </a>

</blockquote>
:::

```{=html}
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
```

::: embed-center
<iframe 
    src="https://www.linkedin.com/embed/feed/update/urn:li:ugcPost:7362122859722256384?collapsed=1" 
    height="567" 
    width="504" 
    frameborder="0" 
    allowfullscreen="" 
    title="Embedded post"> </iframe>
:::

![AI Product Management Learning Roadmap from Paweł Huryn](images/ai-pm-roadmap.jpeg)

## Let's Build!

### The Command Line

In order to be a serious AI Product Manager, you need to get comfortable interacting with your computer via the [command line](https://en.wikipedia.org/wiki/Command-line_interface).

The command line is a text-based interface, often called a CLI (Command Line Interface), that lets you control your computer by typing instructions rather than clicking with a mouse, touchpad, or touch screen. Instead of navigating through a graphical user interface (GUI), which is the typical window- and icon-based environment, you enter text commands directly and the computer executes them. This gives you the potential for more precision and speed, plus access to powerful tools that aren’t always available through a GUI.

Using the command line is like having a direct conversation with your computer: you type an instruction (like “open this folder” or “run this program”), and the computer executes it immediately. Developers and data scientists use the command line because it’s faster, more precise, and more powerful for tasks like creating projects, installing software, running code, and automating workflows.

ChatGPT and other LLM-powered generative AI tools have made learning the command line more important, not less. The command line is where you unlock the real power of automation enabling you to run scripts and streamline repetitive tasks.

Furthermore, the command line is the native environment for the industry-leading approach to AI-assisted coding, Claude Code, which we’ll be using throughout this class. By getting comfortable in the command line, you won’t just be learning an old-school developer skill; you’ll be stepping into the same environment where cutting-edge AI coding tools operate, giving you the ability to build, experiment, and ship AI products with confidence.”

Learn by doing. Spend the next 10 minutes exploring the following commands.

**Navigation**

```{python eval=false}
# What folder am I in?: "print working directory"
pwd

# What files are in this folder?: "list"
ls

# Move around: "change directory"
cd foldername
cd ..            # up one level
cd ~             # home folder

# Make things: “make directory”
mkdir my-project

# Create or overwrite a file with text (cross-platform): “repeat back”
# > is like hitting “Save As” and overwriting the file.
echo "Hello AI PMs" > hello.txt

# Append text (cross-platform)
# >> is like hitting “Add to end” (append) — you’re just tacking on more notes.
echo "Second line" >> hello.txt

# Show file contents
cat notes.txt

# Combine files into a new file
cat part1.txt part2.txt > full.txt

# use cat to peek inside a file without leaving the terminal. If you give it more than one file, it glues them together into a single text stream.

# Copy a file: "copy"
cp notes.txt backup.txt

# Remove things: “remove”
rm hello.txt "
rm -r my-project   # remove a folder (careful!)

# Open applications
open -a "Google Chrome" https://claude.ai

# you can leave file name off if you just wanna open a blank instance.
open -a "Microsoft Word" mydoc.docx

```

**Gotchas**

- Paths with spaces: quote them — cd "My Folder" 
- Case sensitivity: macOS/Linux are usually case-sensitive; Windows is not.
- rm is more permanent than dragging something to the Trash/Recycle Bin. By default, it doesn’t send files to a “trash”, it permanently deletes them. Use with caution!

**Package management**

Package management is the system your computer uses to install, update, and remove software through the command line. Instead of hunting down installers on websites and clicking through “Next, Next, Finish,” a package manager lets you type a single command to get the tool you need. This matters because it saves time, keeps your environment consistent, and makes it easy to update everything at once — a huge advantage when you’re building AI products that depend on multiple tools and libraries. Learning to use a package manager (Homebrew on Mac, Winget on Windows) puts you in control of your setup, reduces errors, and helps you work like a professional.


```{python eval=false}
# Mac

# Install Homebrew
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

#confirm it’s set up correctly.
brew doctor

# Install the "htop" system monitor
brew install htop

# Run it to see your system processes
htop
```


```{python eval=false}
# Windows

# winget should be preinstalled on windows
winget --version
# Install the "htop" system monitor
winget install --id=htop

# Run it to see your system processes
htop
```


### VS Code



### Claude Code

### Write a PRD

### Code the app

## Student Demos

## Claude Code Learning Mode

## AI and Machine Learning

You first need to understand something about how this technology works, at least at a high level. Artificial Intelligence (AI) is the broad idea of creating computer systems that can perform tasks we normally associate with human intelligence, like understanding language, recognizing patterns, making decisions, and generating creative content.

Machine Learning (ML) is a subset of AI that focuses on teaching computers to learn from data instead of following hard-coded instructions. In ML, we give the computer many examples (data) and let it find the patterns on its own. The more and better-quality data it sees, the better it gets at making predictions or generating useful outputs.

Within machine learning, deep learning uses layers of artificial “neurons” to handle extremely complex patterns—this is the technology behind most modern breakthroughs, including Large Language Models (LLMs) like ChatGPT.

Even if you won’t be building models yourself, understanding these basic concepts will help you ask the right questions, spot opportunities for AI in products, and work effectively with technical teams.

![Image source: Build a Large Language Model (From Scratch) by Sebastian Raschka](images/ai-ml-map.png)

### Supervised Learning

The branch of machine learning that powers today’s Generative AI breakthroughs is supervised learning. A conceptual example of supervised learning is teaching someone to guess the next word in a sentence by giving them lots of examples with the right answers.

For instance, imagine we train a model on sentences like:

-   The cat sat on the **mat**.
-   She went to the **store**.
-   I like to eat **pizza**.

In each case, the words before the blank are the **input**, and the correct missing word is the **label**. The model makes a guess, checks if it matches the label, and adjusts its internal weights to improve next time.

After seeing millions of examples, the model learns patterns in how words are used so it can predict the missing word—even in sentences it has never seen before.

In short: **supervised learning is learning patterns from labeled examples so you can make accurate predictions on new, unseen data.**

The simplest form of supervised learning is **regression**, where the goal is to predict a number based on input data. For example, given a set of sentences and their average reading times, a regression model could learn to predict how long it might take someone to read a new sentence. The model trains on many input–output pairs, gradually learning the relationship between the features in the input and the numeric value in the output.

While regression can be done with simple formulas, modern AI—including Large Language Models—relies on **neural networks** to handle far more complex patterns. Neural networks are essentially many layers of interconnected regression-like steps, stacked and tuned to capture relationships in huge datasets.

Understanding these building blocks will help you see how LLMs work under the hood, even if the scale and complexity are much greater than in basic regression.

### Gradient Descent

Gradient descent is the learning process that tunes a model to make better predictions over time. Imagine you’re standing on a foggy hillside and want to get to the lowest point in the valley. You can’t see far, so you take small steps downhill in the steepest direction you can feel under your feet.

In a neural network, the “hill” is the **error**, how wrong the model’s predictions are. The “steps” are **weight adjustments** which change the models predictions. After each guess, the network measures the error, figures out which direction will reduce it the most, and then tweaks the weights slightly to move in that direction.

By repeating this process many times, the network eventually settles in a low spot where the error is as small as possible.

In short: **gradient descent is the process of taking small steps to reduce errors until the model’s predictions are as accurate as it can make them.**
